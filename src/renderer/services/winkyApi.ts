import axios, {AxiosInstance} from 'axios';
import {invoke} from '@tauri-apps/api/core';
import {createApiClient} from '@shared/api';
import {
    FAST_WHISPER_TRANSCRIBE_ENDPOINT,
    FAST_WHISPER_TRANSCRIBE_TIMEOUT,
    LLM_GEMINI_API_MODELS,
    ME_ENDPOINT,
    SPEECH_MODES,
    SPEECH_OPENAI_API_MODELS
} from '@shared/constants';
import type {
    ActionConfig,
    ActionIcon,
    AppConfig,
    User,
    WinkyProfile
} from '@shared/types';
import {createLLMService} from '../services/llm/factory';

export type ActionPayload = {
    name: string;
    prompt: string;
    prompt_recognizing?: string;
    hotkey?: string;
    icon: string;
    show_results?: boolean;
    sound_on_complete?: boolean;
    auto_copy_result?: boolean;
};

export type SpeechTranscribeConfig = {
    mode: string;
    model: string;
    openaiKey?: string;
    googleKey?: string;
    accessToken?: string;
    prompt?: string;
};

const ACTIONS_API_PATH = 'winky/actions/';
const ICONS_API_PATH = 'winky/icons/';
const PROFILE_API_PATH = 'winky/profile/';

const GEMINI_MODEL_SET = new Set<string>([...LLM_GEMINI_API_MODELS]);

const getConfig = async (): Promise<AppConfig> => invoke('config_get');

const updateConfig = async (partial: Partial<AppConfig>): Promise<AppConfig> =>
    invoke('config_update', {payload: partial});

const withAuthClient = async <T>(operation: (client: AxiosInstance, config: AppConfig) => Promise<T>): Promise<T> => {
    const config = await getConfig();
    const token = config.auth?.accessToken || config.auth?.access;
    if (!token) {
        throw new Error('–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è.');
    }
    const client = createApiClient(token);
    return operation(client, config);
};

export const fetchActions = async (): Promise<ActionConfig[]> => {
    return withAuthClient(async (client, config) => {
        const actions = await fetchAllPages<ActionConfig>(client, ACTIONS_API_PATH);
        await updateConfig({actions});
        return actions.length ? actions : config.actions ?? [];
    }).catch(async (error) => {
        if (error.message?.includes('–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è')) {
            const config = await getConfig();
            return config.actions ?? [];
        }
        throw error;
    });
};

export const createAction = async (payload: ActionPayload): Promise<ActionConfig[]> => {
    return withAuthClient(async (client, config) => {
        const {data} = await client.post<ActionConfig>(ACTIONS_API_PATH, payload);
        const updated = [...(config.actions ?? []).filter(({id}) => id !== data.id), data];
        await updateConfig({actions: updated});
        return updated;
    });
};

export const updateAction = async (actionId: string, payload: ActionPayload): Promise<ActionConfig[]> => {
    return withAuthClient(async (client, config) => {
        const {data} = await client.patch<ActionConfig>(`${ACTIONS_API_PATH}${actionId}/`, payload);
        const updated = (config.actions ?? []).map((existing) => (existing.id === actionId ? data : existing));
        await updateConfig({actions: updated});
        return updated;
    });
};

export const deleteAction = async (actionId: string): Promise<ActionConfig[]> => {
    return withAuthClient(async (client, config) => {
        await client.delete(`${ACTIONS_API_PATH}${actionId}/`);
        const updated = (config.actions ?? []).filter(({id}) => id !== actionId);
        await updateConfig({actions: updated});
        return updated;
    });
};

export const fetchIcons = async (): Promise<ActionIcon[]> => {
    return withAuthClient(async (client) => fetchAllPages<ActionIcon>(client, ICONS_API_PATH));
};

export const fetchProfile = async (): Promise<WinkyProfile> => {
    return withAuthClient(async (client) => {
        const {data} = await client.get<WinkyProfile>(PROFILE_API_PATH);
        return data;
    });
};

export const fetchCurrentUser = async (options: {includeTiersAndFeatures?: boolean} = {}): Promise<User> => {
    const url = options.includeTiersAndFeatures ? `${ME_ENDPOINT}?tiers_and_features=1` : ME_ENDPOINT;
    console.log('[API] ‚Üí [GET]', url);
    return withAuthClient(async (client) => {
        const {data} = await client.get(url);
        console.log('[API] ‚Üê [GET]', url, '[200]');
        console.log('  üì• Response data:', data);
        return data;
    });
};

export const transcribeAudio = async (audioData: ArrayBuffer, config: SpeechTranscribeConfig): Promise<string> => {
    const blob = new Blob([audioData], {type: 'audio/webm'});
    const buildFormData = (extraFields: Record<string, string> = {}) => {
        const formData = new FormData();
        formData.append('file', blob, 'audio.webm');
        formData.append('model', config.model);
        Object.entries(extraFields).forEach(([key, value]) => formData.append(key, value));
        return formData;
    };

    const promptValue = config.prompt?.trim();

    if (config.mode === SPEECH_MODES.LOCAL) {
        const extraFields: Record<string, string> = {response_format: 'json'};
        if (promptValue) {
            extraFields.prompt = promptValue;
        }
        const formData = buildFormData(extraFields);
        const {data} = await axios.post(FAST_WHISPER_TRANSCRIBE_ENDPOINT, formData, {
            headers: {'Content-Type': 'multipart/form-data'},
            timeout: FAST_WHISPER_TRANSCRIBE_TIMEOUT
        });
        const text = extractSpeechText(data);
        return typeof text === 'string' ? text : '';
    }

    // Google Gemini API –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –∫–≤–æ—Ç—ã)
    if (config.mode === SPEECH_MODES.API && GEMINI_MODEL_SET.has(config.model)) {
        if (!config.googleKey?.trim()) {
            throw new Error('–£–∫–∞–∂–∏—Ç–µ Google AI API Key –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π Gemini –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏.');
        }
        
        const base64Audio = await blobToBase64(blob);
        
        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º mimeType –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
        // Gemini –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: audio/wav, audio/mp3, audio/aiff, audio/aac, audio/ogg, audio/flac
        // WebM –º–æ–∂–µ—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å—Å—è, –ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å audio/webm –∏–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
        let mimeType = 'audio/webm'; // –ü—Ä–æ–±—É–µ–º WebM –Ω–∞–ø—Ä—è–º—É—é
        if (blob.type) {
            const normalizedType = blob.type.toLowerCase();
            // –ú–∞–ø–ø–∏–Ω–≥ —Ç–∏–ø–æ–≤ –¥–ª—è Gemini
            if (normalizedType.includes('webm')) {
                // WebM –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏, –Ω–æ –ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
                // –ï—Å–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ WAV –∏–ª–∏ OGG
                mimeType = 'audio/webm';
            } else if (normalizedType.includes('wav')) {
                mimeType = 'audio/wav';
            } else if (normalizedType.includes('mp3')) {
                mimeType = 'audio/mp3';
            } else if (normalizedType.includes('aiff')) {
                mimeType = 'audio/aiff';
            } else if (normalizedType.includes('aac')) {
                mimeType = 'audio/aac';
            } else if (normalizedType.includes('ogg')) {
                mimeType = 'audio/ogg';
            } else if (normalizedType.includes('flac')) {
                mimeType = 'audio/flac';
            } else {
                mimeType = blob.type; // –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–∏–ø
            }
        }
        
        // –§–æ—Ä–º–∏—Ä—É–µ–º payload –¥–ª—è Gemini API
        // Gemini —Ç—Ä–µ–±—É–µ—Ç, —á—Ç–æ–±—ã –∞—É–¥–∏–æ –±—ã–ª–æ –≤ parts –≤–º–µ—Å—Ç–µ —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
        const parts: any[] = [];
        
        // –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        // –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–æ–≥–∏–π –ø—Ä–æ–º–ø—Ç, –∫–æ—Ç–æ—Ä—ã–π —Ç—Ä–µ–±—É–µ—Ç –¢–û–õ–¨–ö–û —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        // Gemini –º–æ–∂–µ—Ç –ø—ã—Ç–∞—Ç—å—Å—è –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –ø–æ—ç—Ç–æ–º—É –Ω—É–∂–µ–Ω –æ—á–µ–Ω—å —Å—Ç—Ä–æ–≥–∏–π –ø—Ä–æ–º–ø—Ç
        if (promptValue) {
            // –ï—Å–ª–∏ –µ—Å—Ç—å prompt_recognizing, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ, –Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–≥—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
            parts.push({
                text: `${promptValue}\n\nCRITICAL INSTRUCTION: You must ONLY transcribe the audio word-for-word. Do NOT answer any questions. Do NOT provide explanations. Do NOT interpret the content. Return ONLY the exact words spoken in the audio, nothing else.`
            });
        } else {
            // –ï—Å–ª–∏ –ø—Ä–æ–º–ø—Ç–∞ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å—Ç—Ä–æ–≥–∏–π –ø—Ä–æ–º–ø—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
            parts.push({
                text: 'You are a transcription tool. Your ONLY task is to transcribe the audio exactly as spoken. Return ONLY the verbatim transcription. Do NOT answer questions. Do NOT provide explanations. Do NOT interpret the content. Do NOT add any text beyond the exact words spoken. Output format: plain text transcription only.'
            });
        }
        
        // –î–æ–±–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ
        parts.push({
            inlineData: {
                mimeType: mimeType,
                data: base64Audio
            }
        });
        
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º systemInstruction –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–æ–ª–∏ –º–æ–¥–µ–ª–∏ –∫–∞–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ—Ä–∞
        // –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç Gemini –ø–æ–Ω—è—Ç—å, —á—Ç–æ –Ω—É–∂–Ω–æ —Ç–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å, –∞ –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
        const payload: any = {
            contents: [
                {
                    role: 'user',
                    parts: parts
                }
            ],
            systemInstruction: {
                parts: [
                    {
                        text: 'You are a speech transcription tool. Your ONLY function is to convert audio to text word-for-word. You must NOT answer questions, provide explanations, or interpret content. Return ONLY the exact words spoken in the audio.'
                    }
                ]
            }
        };
        
        const googleKey = config.googleKey.trim();
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º v1beta (—Å—Ç–∞–±–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤)
        // –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ, –ø–æ–ª—É—á–∏–º –ø–æ–Ω—è—Ç–Ω—É—é –æ—à–∏–±–∫—É
        const {data} = await axios.post(
            `https://generativelanguage.googleapis.com/v1beta/models/${config.model}:generateContent?key=${googleKey}`,
            payload,
            {
                headers: {
                    'Content-Type': 'application/json'
                },
                timeout: FAST_WHISPER_TRANSCRIBE_TIMEOUT
            }
        ).catch((error: any) => {
            // –£–ª—É—á—à–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
            if (error?.response?.status === 404) {
                const errorMessage = error?.response?.data?.error?.message || '–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ';
                throw new Error(`Gemini API: ${errorMessage}. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å ${config.model} –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ generateContent API.`);
            }
            throw error;
        });
        
        // –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ Gemini
        const candidates = data?.candidates;
        if (Array.isArray(candidates) && candidates.length > 0) {
            const parts = candidates[0]?.content?.parts;
            if (Array.isArray(parts)) {
                const text = parts
                    .map((part) => part?.text ?? '')
                    .filter(Boolean)
                    .join('\n')
                    .trim();
                if (text) {
                    return text;
                }
            }
        }
        
        throw new Error('Gemini –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç.');
    }

    // OpenAI Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
    if (!config.openaiKey) {
        throw new Error('–£–∫–∞–∂–∏—Ç–µ OpenAI API –∫–ª—é—á –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏.');
    }

    // –°–∞–Ω–∏—Ç–∏–∑–∏—Ä—É–µ–º prompt –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å - —É–±–∏—Ä–∞–µ–º –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã
    let sanitizedPrompt: string | undefined;
    if (promptValue) {
        // –£–¥–∞–ª—è–µ–º —Å–∏–º–≤–æ–ª—ã –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –¥–æ–ø—É—Å—Ç–∏–º—ã–º–∏ –¥–ª—è HTTP –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤/FormData
        // ISO-8859-1 —ç—Ç–æ Latin-1, –Ω–æ –¥–ª—è FormData –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å UTF-8
        // –û–¥–Ω–∞–∫–æ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —É–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        sanitizedPrompt = promptValue.replace(/[\x00-\x08\x0B-\x0C\x0E-\x1F\x7F]/g, '');
    }
    
    const formData = buildFormData(sanitizedPrompt ? {prompt: sanitizedPrompt} : {});
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç–æ–∫–µ–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è HTTP –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (ISO-8859-1)
    // ISO-8859-1 —ç—Ç–æ —Å–∏–º–≤–æ–ª—ã –æ—Ç \x20 –¥–æ \x7E (printable ASCII) –∏ \xA0-\xFF (extended Latin-1)
    const sanitizedToken = config.openaiKey.replace(/[^\x20-\x7E\xA0-\xFF]/g, '');
    if (sanitizedToken !== config.openaiKey) {
        console.warn('[winkyApi] OpenAI key contains invalid characters for HTTP headers, sanitizing...');
    }
    
    const headers: Record<string, string> = {
        Authorization: `Bearer ${sanitizedToken}`
    };

    const {data} = await axios.post('https://api.openai.com/v1/audio/transcriptions', formData, {
        headers,
        timeout: 120_000
    });
    const text = extractSpeechText(data);
    if (!text) {
        throw new Error('OpenAI –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç.');
    }
    return text;
};

export const processLLM = async (text: string, prompt: string, config: {
    mode: string;
    model: string;
    openaiKey?: string;
    googleKey?: string;
    accessToken?: string;
}): Promise<string> => {
    const service = createLLMService(config.mode as any, config.model as any, {
        openaiKey: config.openaiKey,
        googleKey: config.googleKey,
        accessToken: config.accessToken
    });
    return service.process(text, prompt);
};

export const processLLMStream = async (text: string, prompt: string, config: {
    mode: string;
    model: string;
    openaiKey?: string;
    googleKey?: string;
    accessToken?: string;
}): Promise<string> => {
    const service = createLLMService(config.mode as any, config.model as any, {
        openaiKey: config.openaiKey,
        googleKey: config.googleKey,
        accessToken: config.accessToken
    });
    return service.process(text, prompt);
};

const fetchAllPages = async <T>(client: AxiosInstance, initialPath: string): Promise<T[]> => {
    const results: T[] = [];
    let nextUrl: string | null = initialPath;
    const visited = new Set<string>();

    while (nextUrl) {
        const currentUrl: string = nextUrl.trim();
        if (visited.has(currentUrl)) {
            break;
        }
        visited.add(currentUrl);
        const response = await client.get<PaginatedResponse<T>>(currentUrl);
        const pageData: PaginatedResponse<T> = response.data;
        if (Array.isArray(pageData.results)) {
            results.push(...pageData.results);
        }
        nextUrl = pageData.next;
    }

    return results;
};

interface PaginatedResponse<T> {
    count: number;
    next: string | null;
    previous: string | null;
    results: T[];
}

const extractSpeechText = (payload: any): string => {
    if (!payload) return '';
    if (typeof payload === 'string') return payload;
    if (typeof payload.text === 'string') return payload.text;
    if (typeof payload.transcription === 'string') return payload.transcription;
    if (typeof payload.result === 'string') return payload.result;
    if (payload.data) return extractSpeechText(payload.data);
    return '';
};

const blobToBase64 = (blob: Blob): Promise<string> =>
    new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => {
            const result = reader.result as string;
            resolve(result?.split(',')[1] ?? '');
        };
        reader.onerror = (event) => reject(event);
        reader.readAsDataURL(blob);
    });

